# -*- coding: utf-8 -*-
"""whisper_tiny (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DOHUsFBgUiXWr9E9i4q6sIu6EOlXd9Z5
"""

!pip install -U transformers
!pip install pandas numpy torch torchaudio transformers evaluate jiwer tqdm
!pip install evaluate
!pip install jiwer
!pip install tqdm

"""## Local Inference on GPU
Model page: https://huggingface.co/openai/whisper-tiny

âš ï¸ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/openai/whisper-tiny)
			and/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) ðŸ™
"""

from google.colab import drive
drive.mount('/content/drive')
PROJECT_ROOT_PATH = "/content/drive/MyDrive/ASR_Project" # Changed for Colab

import os
import pandas as pd
import numpy as np # Still useful for general numerical operations
import torch # Still needed for Whisper model
import torchaudio # Still needed for audio loading

# For WER calculation
from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq
import evaluate # Hugging Face evaluate library
import jiwer # For robust WER calculation
from tqdm import tqdm
import traceback # Import traceback for detailed error logging
import string
# Set environment variable to suppress symlink warning from Hugging Face Hub
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
print("Environment variable HF_HUB_DISABLE_SYMLINKS_WARNING set to 1 for this process.")

# --- Configuration ---

# Path to your master CSV for LibriSpeech test-clean
METADATA_CSV_PATH = os.path.join(PROJECT_ROOT_PATH, "librispeech_test_metadata.csv")

# Base directories for different datasets
# ORIGINAL_DATA_DIR is now PROJECT_ROOT_PATH because the CSV's relative_path
# likely includes 'test-clean/' (e.g., 'test-clean/speaker_id/...')
ORIGINAL_DATA_DIR = PROJECT_ROOT_PATH
ANONYMIZED_DATA_ROOT = os.path.join(PROJECT_ROOT_PATH) # Contains Anon_data_McAdams_Fixed etc.

# Anonymization folder names and suffixes
FIXED_ANON_FOLDER = 'Anon_data_McAdams_Fixed'
FIXED_ANON_SUFFIX = '_fixed_0.80'
DYNAMIC_ANON_FOLDER = 'Anon_data_McAdams_Dynamic'
DYNAMIC_ANON_SUFFIX = '_dynamic_0.70_0.90'
RANDOM_ANON_FOLDER = 'Anon_data_McAdams_Random'
RANDOM_ANON_SUFFIX = '_random_uniform'

# --- Initialize Whisper Model (for WER) ---
try:
    processor = AutoProcessor.from_pretrained("openai/whisper-base")
    model = AutoModelForSpeechSeq2Seq.from_pretrained("openai/whisper-base")

    # Move model to GPU if available
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    print(f"Whisper ASR model 'openai/whisper-base' loaded successfully on {device}.")
except Exception as e:
    # Print the error for debugging before exiting
    print(f"Error loading Whisper model: {e}")
    exit()

# Initialize WER metric
wer_metric = evaluate.load("wer")

# --- Helper Functions ---

def normalize_text(text):
    """
    Normalizes text by converting to uppercase and removing punctuation.
    """
    # Convert to uppercase
    text = text.upper()
    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    # Remove extra spaces
    text = ' '.join(text.split())
    return text

def get_file_path(base_dir, relative_path_in_csv, anonymization_suffix=None, target_audio_extension=".flac"):
    """
    Constructs the full file path based on dataset type and anonymization.
    """
    # Normalize path separators for splitting, assuming CSV uses '/' or '\'
    normalized_relative_path = relative_path_in_csv.replace('\\', '/').replace('/', os.sep)
    parts = normalized_relative_path.split(os.sep)

    if anonymization_suffix:
        if len(parts) >= 4: # Expecting at least test-clean/speaker/chapter/file
            test_clean_dir = parts[0]
            speaker_id_dir = parts[1]
            chapter_id_dir = parts[2]
            filename_with_ext = parts[3]

            new_chapter_id_dir = f"{chapter_id_dir}{anonymization_suffix}"
            filename_base = os.path.splitext(filename_with_ext)[0]

            # Filename does NOT get the suffix, only its extension changed
            new_filename_with_ext = f"{filename_base}{target_audio_extension}"

            # Reconstruct the relative path for the actual file on disk
            # Retain 'test-clean' as per user's clarified structure
            actual_relative_path = os.path.join(test_clean_dir, speaker_id_dir, new_chapter_id_dir, new_filename_with_ext)
        else:
            # Fallback if path format is unexpected for anonymized data
            actual_relative_path = os.path.splitext(normalized_relative_path)[0] + target_audio_extension
    else:
        # For original data, just ensure correct extension (should be .flac)
        actual_relative_path = os.path.splitext(normalized_relative_path)[0] + target_audio_extension

    return os.path.join(base_dir, actual_relative_path)


# --- Main WER Calculation Logic ---

def run_wer_evaluation(metadata_path, data_root_dir, anonymization_suffix=None, target_audio_extension=".flac"):
    """
    Runs the WER evaluation for a given dataset.

    Args:
        metadata_path (str): Path to the CSV metadata file.
        data_root_dir (str): Root directory where audio files are stored.
        anonymization_suffix (str, optional): The suffix to append to chapter IDs and filenames
                                              for anonymized data (e.g., "_fixed_0.80").
                                              Defaults to None for original data.
        target_audio_extension (str): The expected file extension for audio files in this dataset
                                      (e.g., ".flac" or ".wav").
    """
    print(f"\n--- Starting WER evaluation for data in: {data_root_dir} ---")
    df = pd.read_csv(metadata_path)

    predictions = []
    references = []

    # Iterate through all entries in the DataFrame for WER calculation
    for index, row in tqdm(df.iterrows(), total=len(df), desc="WER Transcription"):
        file_path = get_file_path(data_root_dir, row['relative_path'], anonymization_suffix, target_audio_extension)
        ground_truth_transcript = row['transcript']

        if not os.path.exists(file_path):
            print(f"Warning: Audio file not found for WER: {file_path}. Skipping.")
            continue # Skip if file doesn't exist

        try:
            # Load audio using torchaudio and ensure correct sample rate for Whisper (16kHz)
            waveform, sample_rate = torchaudio.load(file_path)
            if sample_rate != 16000:
                resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)
                waveform = resampler(waveform)
            if waveform.shape[0] > 1: # Convert to mono if stereo
                waveform = waveform.mean(dim=0, keepdim=True)

            # Process audio input for the model using the processor
            # The processor expects a 1D numpy array for audio input
            input_features = processor(waveform.squeeze(0).numpy(), sampling_rate=16000, return_tensors="pt").input_features

            # Move input features to the correct device (CPU/GPU)
            input_features = input_features.to(device)

            # Generate token IDs using the model
            # `return_timestamps=True` is handled by the model's generation configuration
            predicted_ids = model.generate(input_features)

            # Decode token IDs to text
            predicted_text = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]

            # Normalize both predicted and ground truth text
            normalized_predicted_text = normalize_text(predicted_text)
            normalized_ground_truth_transcript = normalize_text(ground_truth_transcript)

            predictions.append(normalized_predicted_text)
            references.append(normalized_ground_truth_transcript)

        except Exception as e:
            print(f"Error transcribing {file_path}: {e}")
            traceback.print_exc() # Print full traceback for detailed error info
            continue

    if not predictions:
        print("No successful transcriptions for WER calculation. Please check file paths and audio integrity.")
        return None

    # Calculate WER
    wer_score = wer_metric.compute(predictions=predictions, references=references)

    print(f"\n--- WER Calculation Complete ---")
    print(f"WER for {os.path.basename(data_root_dir)}: {wer_score:.4f}")
    return wer_score


# --- Run WER for Original Data ---
print("\nStarting WER calculation for ORIGINAL data...")
original_wer = run_wer_evaluation(METADATA_CSV_PATH, ORIGINAL_DATA_DIR,
                                  anonymization_suffix=None, target_audio_extension=".flac")

# --- Run WER for Fixed Anonymized Data ---
print("\nStarting WER calculation for FIXED ANONYMIZED data...")
fixed_anon_data_dir = os.path.join(ANONYMIZED_DATA_ROOT, FIXED_ANON_FOLDER)
fixed_anon_wer = run_wer_evaluation(METADATA_CSV_PATH, fixed_anon_data_dir,
                                    anonymization_suffix=FIXED_ANON_SUFFIX, target_audio_extension=".wav")

# --- Run WER for Dynamic Anonymized Data ---
print("\nStarting WER calculation for DYNAMIC ANONYMIZED data...")
dynamic_anon_data_dir = os.path.join(ANONYMIZED_DATA_ROOT, DYNAMIC_ANON_FOLDER)
dynamic_anon_wer = run_wer_evaluation(METADATA_CSV_PATH, dynamic_anon_data_dir,
                                      anonymization_suffix=DYNAMIC_ANON_SUFFIX, target_audio_extension=".wav")

# --- Run WER for Random Anonymized Data ---
print("\nStarting WER calculation for RANDOM ANONYMIZED data...")
random_anon_data_dir = os.path.join(ANONYMIZED_DATA_ROOT, RANDOM_ANON_FOLDER)
random_anon_wer = run_wer_evaluation(METADATA_CSV_PATH, random_anon_data_dir,
                                     anonymization_suffix=RANDOM_ANON_SUFFIX, target_audio_extension=".wav")

# --- Print Summary of Results ---
print("\n--- Summary of WER Results ---")
if original_wer is not None:
    print(f"Original Data WER: {original_wer:.4f}")
if fixed_anon_wer is not None:
    print(f"Fixed Anonymized Data WER: {fixed_anon_wer:.4f}")
if dynamic_anon_wer is not None:
    print(f"Dynamic Anonymized Data WER: {dynamic_anon_wer:.4f}")
if random_anon_wer is not None:
    print(f"Random Anonymized Data WER: {random_anon_wer:.4f}")